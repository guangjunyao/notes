<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2017-05-28 Sun 11:56 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="viewport" content="width=device-width, initial-scale=1" />
<title></title>
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="weiwu" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgheadline11">1. Week 1</a>
<ul>
<li><a href="#orgheadline1">1.1. What is machine learning</a></li>
<li><a href="#orgheadline2">1.2. Well defined machine learning problem</a></li>
<li><a href="#orgheadline5">1.3. Decision tree learning</a>
<ul>
<li><a href="#orgheadline3">1.3.1. Top-Down induction of DTree</a></li>
<li><a href="#orgheadline4">1.3.2. Entropy</a></li>
</ul>
</li>
<li><a href="#orgheadline6">1.4. Course logistics</a></li>
<li><a href="#orgheadline7">1.5. Model Representation</a></li>
<li><a href="#orgheadline8">1.6. Cost Function</a></li>
<li><a href="#orgheadline9">1.7. Linear Regression with One Variable</a></li>
<li><a href="#orgheadline10">1.8. Linear Algebra Review</a></li>
</ul>
</li>
<li><a href="#orgheadline12">2. Week 2 Linear Regression with Multiple Variables</a></li>
<li><a href="#orgheadline18">3. Week 3</a>
<ul>
<li><a href="#orgheadline13">3.1. Logistic Regression</a></li>
<li><a href="#orgheadline14">3.2. Regularization</a></li>
<li><a href="#orgheadline17">3.3. Classification</a>
<ul>
<li><a href="#orgheadline15">3.3.1. Linear Discriminant Analysis</a></li>
<li><a href="#orgheadline16">3.3.2. Comparison</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgheadline20">4. Week 4</a>
<ul>
<li><a href="#orgheadline19">4.1. Neural Networks: Representation</a></li>
</ul>
</li>
<li><a href="#orgheadline22">5. Week 5</a>
<ul>
<li><a href="#orgheadline21">5.1. Neural Networks: Learning</a></li>
</ul>
</li>
<li><a href="#orgheadline25">6. Week 6</a>
<ul>
<li><a href="#orgheadline23">6.1. Advice for Applying Machine Learning</a></li>
<li><a href="#orgheadline24">6.2. Machine Learning System Design</a></li>
</ul>
</li>
<li><a href="#orgheadline30">7. Week 7</a>
<ul>
<li><a href="#orgheadline29">7.1. Support Vector Machine</a>
<ul>
<li><a href="#orgheadline26">7.1.1. Maximal Margin Classifier</a></li>
<li><a href="#orgheadline27">7.1.2. Support Vector Classifiers</a></li>
<li><a href="#orgheadline28">7.1.3. Support Vector Machines</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgheadline33">8. Week 8</a>
<ul>
<li><a href="#orgheadline31">8.1. Unsupervised Learning</a></li>
<li><a href="#orgheadline32">8.2. Dimensionality Reduction</a></li>
</ul>
</li>
<li><a href="#orgheadline36">9. Week 9</a>
<ul>
<li><a href="#orgheadline34">9.1. Anomaly Detection</a></li>
<li><a href="#orgheadline35">9.2. Recommender Systems</a></li>
</ul>
</li>
<li><a href="#orgheadline38">10. Week 10</a>
<ul>
<li><a href="#orgheadline37">10.1. Large Scale Machine Learning</a></li>
</ul>
</li>
<li><a href="#orgheadline40">11. Week 11</a>
<ul>
<li><a href="#orgheadline39">11.1. Application Example: Photo OCR</a></li>
</ul>
</li>
<li><a href="#orgheadline43">12. Tree-Based Methods</a>
<ul>
<li><a href="#orgheadline41">12.1. Decision Trees</a></li>
<li><a href="#orgheadline42">12.2. Bagging, Random Forests, Boosting</a></li>
</ul>
</li>
<li><a href="#orgheadline48">13. Unsupervised Learning</a>
<ul>
<li><a href="#orgheadline44">13.1. Principal Components Analysis</a></li>
<li><a href="#orgheadline47">13.2. Clustering Methods</a>
<ul>
<li><a href="#orgheadline45">13.2.1. K-Means Clustering</a></li>
<li><a href="#orgheadline46">13.2.2. Hierarchical Clustering</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgheadline51">14. Resampling Methods</a>
<ul>
<li><a href="#orgheadline49">14.1. Cross-Validation</a></li>
<li><a href="#orgheadline50">14.2. The Bootstrap</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-orgheadline11" class="outline-2">
<h2 id="orgheadline11"><span class="section-number-2">1</span> Week 1</h2>
<div class="outline-text-2" id="text-1">
</div><div id="outline-container-orgheadline1" class="outline-3">
<h3 id="orgheadline1"><span class="section-number-3">1.1</span> What is machine learning</h3>
<div class="outline-text-3" id="text-1-1">
<p>
Study of algorithms that
</p>
<ul class="org-ul">
<li>improve their performance P</li>
<li>at some task T</li>
</ul>
<p>
training data set, validation data set, test data set.
</p>
<ul class="org-ul">
<li>with experience E</li>
</ul>
</div>
</div>

<div id="outline-container-orgheadline2" class="outline-3">
<h3 id="orgheadline2"><span class="section-number-3">1.2</span> Well defined machine learning problem</h3>
<div class="outline-text-3" id="text-1-2">
<ul class="org-ul">
<li>supervised learning</li>
<li>unsupervised learning</li>
</ul>
</div>
</div>

<div id="outline-container-orgheadline5" class="outline-3">
<h3 id="orgheadline5"><span class="section-number-3">1.3</span> Decision tree learning</h3>
<div class="outline-text-3" id="text-1-3">
<p>
\[H = {H|h: X \to Y}\]
</p>
</div>

<div id="outline-container-orgheadline3" class="outline-4">
<h4 id="orgheadline3"><span class="section-number-4">1.3.1</span> Top-Down induction of DTree</h4>
<div class="outline-text-4" id="text-1-3-1">
<ul class="org-ul">
<li>A &rarr; the best decision attribute for next node.</li>
<li>Assign A as decision attribute for node.</li>
<li>For each value of A, create new descendant of node.</li>
<li>Sort training examples to leaf nodes.</li>
<li>If training examples perfectly classified, then STOP, Else iterate over new leaf nodes.</li>
</ul>
</div>
</div>

<div id="outline-container-orgheadline4" class="outline-4">
<h4 id="orgheadline4"><span class="section-number-4">1.3.2</span> Entropy</h4>
<div class="outline-text-4" id="text-1-3-2">
<p>
Entropy H(X) of a random variable X:
\[H(X) = -\Sum{P(X=i)log_2*P(X=i)}\]
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline6" class="outline-3">
<h3 id="orgheadline6"><span class="section-number-3">1.4</span> Course logistics</h3>
<div class="outline-text-3" id="text-1-4">
<ul class="org-ul">
<li>Linear Regression</li>
<li>Logistic Regression</li>
<li>Neural Networks</li>
<li>Support Vector Machines</li>
<li>K-means Clustering</li>
<li>Principal Components Analysis</li>
<li>Anomaly Detection</li>
<li>Collaborative Filtering</li>
<li>Object Recognition</li>
</ul>
</div>
</div>

<div id="outline-container-orgheadline7" class="outline-3">
<h3 id="orgheadline7"><span class="section-number-3">1.5</span> Model Representation</h3>
<div class="outline-text-3" id="text-1-5">
<p>
To establish notation for future use, we’ll use x(i) to denote the “input” variables (living area in this example),
also called input features, and y(i) to denote the “output” or target variable that we are trying to predict (price).
(x(i),y(i)) is called a training example.
m—is called a training set.
</p>
</div>
</div>

<div id="outline-container-orgheadline8" class="outline-3">
<h3 id="orgheadline8"><span class="section-number-3">1.6</span> Cost Function</h3>
<div class="outline-text-3" id="text-1-6">
<p>
\(J(\Theta_1,\Theta_2)\)
contour is the bow projected on the 2D surface.
A contour plot is a graph that contains many contour lines. A contour line of a two variable function has a constant value at all points of the same line.
</p>
</div>
</div>

<div id="outline-container-orgheadline9" class="outline-3">
<h3 id="orgheadline9"><span class="section-number-3">1.7</span> Linear Regression with One Variable</h3>
</div>

<div id="outline-container-orgheadline10" class="outline-3">
<h3 id="orgheadline10"><span class="section-number-3">1.8</span> Linear Algebra Review</h3>
<div class="outline-text-3" id="text-1-8">
<ul class="org-ul">
<li>Vector</li>
<li>Matrix</li>
<li></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgheadline12" class="outline-2">
<h2 id="orgheadline12"><span class="section-number-2">2</span> Week 2 Linear Regression with Multiple Variables</h2>
<div class="outline-text-2" id="text-2">
<ul class="org-ul">
<li>Gradient Descent:</li>
</ul>
<p>
Taking the derivative (the tangential line to a function) of our cost function.
The slope of the tangent is the derivative at that point and it will give us a direction to move towards.
We make steps down the cost function in the direction with the steepest descent.
The size of each step is determined by the parameter α, which is called the learning rate.
</p>
<ul class="org-ul">
<li>Algorithm:</li>
</ul>
<p>
\[\Theta_j = \Theta_j + \Alpha\Derivative{J(\Theta_0,\Theta_1)}\]
Update simutaneously:
\[Temp_0 := \Theta_0 - \Alpha\Derivative{J(\Theta_0,\Theta_1)} \]
\[Temp_1 := \Theta_1 - \Alpha\Derivative{J(\Theta_0,\Theta_1)} \]
</p>
<ul class="org-ul">
<li>normalization</li>
</ul>
<p>
\[\theta_0 = \theta_0 - \alpha\partial{J(\theta)}{\theta}\]
</p>
</div>
</div>
<div id="outline-container-orgheadline18" class="outline-2">
<h2 id="orgheadline18"><span class="section-number-2">3</span> Week 3</h2>
<div class="outline-text-2" id="text-3">
</div><div id="outline-container-orgheadline13" class="outline-3">
<h3 id="orgheadline13"><span class="section-number-3">3.1</span> Logistic Regression</h3>
</div>
<div id="outline-container-orgheadline14" class="outline-3">
<h3 id="orgheadline14"><span class="section-number-3">3.2</span> Regularization</h3>
</div>
<div id="outline-container-orgheadline17" class="outline-3">
<h3 id="orgheadline17"><span class="section-number-3">3.3</span> Classification</h3>
<div class="outline-text-3" id="text-3-3">
</div><div id="outline-container-orgheadline15" class="outline-4">
<h4 id="orgheadline15"><span class="section-number-4">3.3.1</span> Linear Discriminant Analysis</h4>
</div>

<div id="outline-container-orgheadline16" class="outline-4">
<h4 id="orgheadline16"><span class="section-number-4">3.3.2</span> Comparison</h4>
</div>
</div>
</div>
<div id="outline-container-orgheadline20" class="outline-2">
<h2 id="orgheadline20"><span class="section-number-2">4</span> Week 4</h2>
<div class="outline-text-2" id="text-4">
</div><div id="outline-container-orgheadline19" class="outline-3">
<h3 id="orgheadline19"><span class="section-number-3">4.1</span> Neural Networks: Representation</h3>
</div>
</div>
<div id="outline-container-orgheadline22" class="outline-2">
<h2 id="orgheadline22"><span class="section-number-2">5</span> Week 5</h2>
<div class="outline-text-2" id="text-5">
</div><div id="outline-container-orgheadline21" class="outline-3">
<h3 id="orgheadline21"><span class="section-number-3">5.1</span> Neural Networks: Learning</h3>
</div>
</div>
<div id="outline-container-orgheadline25" class="outline-2">
<h2 id="orgheadline25"><span class="section-number-2">6</span> Week 6</h2>
<div class="outline-text-2" id="text-6">
</div><div id="outline-container-orgheadline23" class="outline-3">
<h3 id="orgheadline23"><span class="section-number-3">6.1</span> Advice for Applying Machine Learning</h3>
</div>
<div id="outline-container-orgheadline24" class="outline-3">
<h3 id="orgheadline24"><span class="section-number-3">6.2</span> Machine Learning System Design</h3>
</div>
</div>
<div id="outline-container-orgheadline30" class="outline-2">
<h2 id="orgheadline30"><span class="section-number-2">7</span> Week 7</h2>
<div class="outline-text-2" id="text-7">
</div><div id="outline-container-orgheadline29" class="outline-3">
<h3 id="orgheadline29"><span class="section-number-3">7.1</span> Support Vector Machine</h3>
<div class="outline-text-3" id="text-7-1">
<p>
Support vector machines (SVMs) are a set of related supervised learning methods used for classification and regression.
Given a set of training examples, each marked as belonging to one of two categories,
an SVM training algorithm builds a model that predicts whether a new example falls into one category or the other.
</p>
</div>

<div id="outline-container-orgheadline26" class="outline-4">
<h4 id="orgheadline26"><span class="section-number-4">7.1.1</span> Maximal Margin Classifier</h4>
</div>

<div id="outline-container-orgheadline27" class="outline-4">
<h4 id="orgheadline27"><span class="section-number-4">7.1.2</span> Support Vector Classifiers</h4>
</div>

<div id="outline-container-orgheadline28" class="outline-4">
<h4 id="orgheadline28"><span class="section-number-4">7.1.3</span> Support Vector Machines</h4>
<div class="outline-text-4" id="text-7-1-3">
<div class="org-src-container">

<pre class="src src-emacs-lisp">from sklearn import svm
training_X = target
training_y = target names
svm_model = svm.SVC<span style="color: #AE81FF;">(</span>gamma=0.01, C=100.<span style="color: #AE81FF;">)</span>
svm_model.fit<span style="color: #AE81FF;">(</span>training_X, training_y<span style="color: #AE81FF;">)</span>
predicts = svm_model.predict<span style="color: #AE81FF;">(</span>test_X<span style="color: #AE81FF;">)</span>
from sklearn.metrics import accuracy_score
accuracy_score<span style="color: #AE81FF;">(</span>y_true, predicts<span style="color: #AE81FF;">)</span>
</pre>
</div>
</div>
</div>
</div>
</div>
<div id="outline-container-orgheadline33" class="outline-2">
<h2 id="orgheadline33"><span class="section-number-2">8</span> Week 8</h2>
<div class="outline-text-2" id="text-8">
</div><div id="outline-container-orgheadline31" class="outline-3">
<h3 id="orgheadline31"><span class="section-number-3">8.1</span> Unsupervised Learning</h3>
</div>
<div id="outline-container-orgheadline32" class="outline-3">
<h3 id="orgheadline32"><span class="section-number-3">8.2</span> Dimensionality Reduction</h3>
</div>
</div>
<div id="outline-container-orgheadline36" class="outline-2">
<h2 id="orgheadline36"><span class="section-number-2">9</span> Week 9</h2>
<div class="outline-text-2" id="text-9">
</div><div id="outline-container-orgheadline34" class="outline-3">
<h3 id="orgheadline34"><span class="section-number-3">9.1</span> Anomaly Detection</h3>
</div>
<div id="outline-container-orgheadline35" class="outline-3">
<h3 id="orgheadline35"><span class="section-number-3">9.2</span> Recommender Systems</h3>
</div>
</div>
<div id="outline-container-orgheadline38" class="outline-2">
<h2 id="orgheadline38"><span class="section-number-2">10</span> Week 10</h2>
<div class="outline-text-2" id="text-10">
</div><div id="outline-container-orgheadline37" class="outline-3">
<h3 id="orgheadline37"><span class="section-number-3">10.1</span> Large Scale Machine Learning</h3>
</div>
</div>
<div id="outline-container-orgheadline40" class="outline-2">
<h2 id="orgheadline40"><span class="section-number-2">11</span> Week 11</h2>
<div class="outline-text-2" id="text-11">
</div><div id="outline-container-orgheadline39" class="outline-3">
<h3 id="orgheadline39"><span class="section-number-3">11.1</span> Application Example: Photo OCR</h3>
</div>
</div>
<div id="outline-container-orgheadline43" class="outline-2">
<h2 id="orgheadline43"><span class="section-number-2">12</span> Tree-Based Methods</h2>
<div class="outline-text-2" id="text-12">
</div><div id="outline-container-orgheadline41" class="outline-3">
<h3 id="orgheadline41"><span class="section-number-3">12.1</span> Decision Trees</h3>
</div>

<div id="outline-container-orgheadline42" class="outline-3">
<h3 id="orgheadline42"><span class="section-number-3">12.2</span> Bagging, Random Forests, Boosting</h3>
</div>
</div>

<div id="outline-container-orgheadline48" class="outline-2">
<h2 id="orgheadline48"><span class="section-number-2">13</span> Unsupervised Learning</h2>
<div class="outline-text-2" id="text-13">
</div><div id="outline-container-orgheadline44" class="outline-3">
<h3 id="orgheadline44"><span class="section-number-3">13.1</span> Principal Components Analysis</h3>
</div>

<div id="outline-container-orgheadline47" class="outline-3">
<h3 id="orgheadline47"><span class="section-number-3">13.2</span> Clustering Methods</h3>
<div class="outline-text-3" id="text-13-2">
<p>
Cluster analysis is the assignment of a set of observations into subsets (called clusters) so that observations within the same cluster are similar according to some predesignated criterion or criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some similarity metric and evaluated for example by internal compactness (similarity between members of the same cluster) and separation between different clusters. Other methods are based on estimated density and graph connectivity. Clustering is a method of unsupervised learning, and a common technique for statistical data analysis.
</p>
</div>

<div id="outline-container-orgheadline45" class="outline-4">
<h4 id="orgheadline45"><span class="section-number-4">13.2.1</span> K-Means Clustering</h4>
</div>

<div id="outline-container-orgheadline46" class="outline-4">
<h4 id="orgheadline46"><span class="section-number-4">13.2.2</span> Hierarchical Clustering</h4>
</div>
</div>
</div>
<div id="outline-container-orgheadline51" class="outline-2">
<h2 id="orgheadline51"><span class="section-number-2">14</span> Resampling Methods</h2>
<div class="outline-text-2" id="text-14">
</div><div id="outline-container-orgheadline49" class="outline-3">
<h3 id="orgheadline49"><span class="section-number-3">14.1</span> Cross-Validation</h3>
</div>

<div id="outline-container-orgheadline50" class="outline-3">
<h3 id="orgheadline50"><span class="section-number-3">14.2</span> The Bootstrap</h3>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Date: <span class="timestamp-wrapper"><span class="timestamp">&lt;2017-05-16 Tue&gt;</span></span></p>
<p class="author">Author: weiwu</p>
<p class="date">Created: 2017-05-28 Sun 11:56</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
