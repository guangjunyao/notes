<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2018-01-02 Tue 15:17 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="viewport" content="width=device-width, initial-scale=1" />
<title></title>
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="weiwu" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="../../styles/demo/css/demo.css"/>
<link href="https://fonts.proxy.ustclug.org/css?family=Roboto+Slab:400,700|Inconsolata:400,700" rel="stylesheet" type="text/css" />
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "left",
        displayIndent: "5em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "left",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgheadline6">1. Overview</a>
<ul>
<li><a href="#orgheadline1">1.1. Sentiment Lexicon and Its Issues</a></li>
<li><a href="#orgheadline2">1.2. Neural Network Architectures</a></li>
<li><a href="#orgheadline3">1.3. Feature Representation</a></li>
<li><a href="#orgheadline5">1.4. Word Embedding</a>
<ul>
<li><a href="#orgheadline4">1.4.1. Increamental training with Gensim.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgheadline9">2. Definition of Sentiment Analysis</a>
<ul>
<li><a href="#orgheadline7">2.1. Structure</a></li>
<li><a href="#orgheadline8">2.2. Opinion Defintion</a></li>
</ul>
</li>
<li><a href="#orgheadline11">3. Language Technology Processing</a>
<ul>
<li><a href="#orgheadline10">3.1. features:</a></li>
</ul>
</li>
<li><a href="#orgheadline18">4. Building the Wikipedia Knowledge Graph in Neo4j</a>
<ul>
<li><a href="#orgheadline12">4.1. Login</a></li>
<li><a href="#orgheadline13">4.2. Approach 1: Loading a reduced subset incrementally through the MediaWiki API</a></li>
<li><a href="#orgheadline17">4.3. Approach 2: Batch loading the data with LOAD CSV from an SQL dump</a>
<ul>
<li><a href="#orgheadline16">4.3.1. Data dumps/Import</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgheadline21">5. TensorBoard: Embedding Visualization</a>
<ul>
<li><a href="#orgheadline19">5.1. Load data</a></li>
<li><a href="#orgheadline20">5.2. Projections</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-orgheadline6" class="outline-2">
<h2 id="orgheadline6"><span class="section-number-2">1</span> Overview</h2>
<div class="outline-text-2" id="text-1">
<p>
<a href="./nlp/NLP.html">Stanford NLP CS224n notes</a>
</p>
<ul class="org-ul">
<li>Document level:</li>
</ul>
<p>
The task at this level is to classify whether a whole opinion document expresses a positive or negative sentiment.
</p>
<ul class="org-ul">
<li>Sentence level:</li>
</ul>
<p>
The task at this level goes to the sentences and determines whether each sentence expressed a positive, negative, or neutral opinion.
</p>

<p>
This level of analysis is closely related to subjectivity classification (Wiebe, Bruce and O'Hara, 1999), which distinguishes sentences (called objective sentences) that express factual information from sentences (called subjective sentences) that express subjective views and opinions.
</p>

<ul class="org-ul">
<li>Entity and Aspect level:</li>
</ul>
<p>
It is based on the idea that an opinion consists of a sentiment (positive or negative) and a target (of opinion).
</p>

<ul class="org-ul">
<li>regular opinions and comparative opinions</li>
</ul>
<p>
A regular opinion expresses a sentiment only on an particular entity or an aspect of the entity, e.g., “Coke tastes very good,” which expresses a positive sentiment on the aspect taste of Coke. A comparative opinion compares multiple entities based on some of their shared aspects, e.g., “Coke tastes better than Pepsi,” which compares Coke and Pepsi based on their tastes (an aspect) and expresses a preference for Coke.
</p>
</div>

<div id="outline-container-orgheadline1" class="outline-3">
<h3 id="orgheadline1"><span class="section-number-3">1.1</span> Sentiment Lexicon and Its Issues</h3>
<div class="outline-text-3" id="text-1-1">
<ul class="org-ul">
<li>lexicon</li>
</ul>
<p>
opinions, positive and negative.
</p>
<ul class="org-ul">
<li>issue</li>
</ul>
<p>
spam review
</p>
<ul class="org-ul">
<li>language structure:</li>
</ul>
<p>
words -&gt; sentences -&gt; paragraphs -&gt; documents.
is your input a string text, or a list of strings, or a list of lists composing by string.
</p>
</div>
</div>
<div id="outline-container-orgheadline2" class="outline-3">
<h3 id="orgheadline2"><span class="section-number-3">1.2</span> Neural Network Architectures</h3>
<div class="outline-text-3" id="text-1-2">
<p>
Feed-forward networks and Recurrent Recursive networks.
</p>
</div>
</div>
<div id="outline-container-orgheadline3" class="outline-3">
<h3 id="orgheadline3"><span class="section-number-3">1.3</span> Feature Representation</h3>
<div class="outline-text-3" id="text-1-3">
<ul class="org-ul">
<li>Input X:</li>
</ul>
<p>
When dealing with natural language, the input x encodes features such as words, part-of-speech tags or other linguistic information. Perhaps the biggest jump when moving from sparse-input linear models to neural-network based models is to stop representing each feature as a unique dimension (the so called one-hot representation) and representing them instead as dense vectors. That is, each core feature is embedded into a d dimensional space, and represented as a vector in that space. The embeddings (the vector representation of each core feature) can then be trained like the other parameter of the function NN.
</p>

<p>
The main benefit of the dense representations is in generalization power: if we believe
some features may provide similar clues, it is worthwhile to provide a representation that
is able to capture these similarities.
</p>

<p>
Probabilities: Dog(10 times) vs Cat(several times), almost no connection from probability. But very similar from dense vectors.
</p>
</div>
</div>


<div id="outline-container-orgheadline5" class="outline-3">
<h3 id="orgheadline5"><span class="section-number-3">1.4</span> Word Embedding</h3>
<div class="outline-text-3" id="text-1-4">
<ul class="org-ul">
<li>Similarity:</li>
</ul>
<p>
We represent word meaning similarity using the meaning of the context words.
</p>
</div>
<div id="outline-container-orgheadline4" class="outline-4">
<h4 id="orgheadline4"><span class="section-number-4">1.4.1</span> Increamental training with Gensim.</h4>
<div class="outline-text-4" id="text-1-4-1">
<div class="org-src-container">

<pre class="src src-python"><span style="color: #FD971F;">model</span> = gensim.models.Word2Vec.load<span style="color: #AE81FF;">(</span><span style="color: #E6DB74;">'/tmp/model/path'</span><span style="color: #AE81FF;">)</span>
model.train<span style="color: #AE81FF;">(</span>more_sentences<span style="color: #AE81FF;">)</span>
</pre>
</div>
</div>
</div>
</div>
</div>

<div id="outline-container-orgheadline9" class="outline-2">
<h2 id="orgheadline9"><span class="section-number-2">2</span> Definition of Sentiment Analysis</h2>
<div class="outline-text-2" id="text-2">
</div><div id="outline-container-orgheadline7" class="outline-3">
<h3 id="orgheadline7"><span class="section-number-3">2.1</span> Structure</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Due to a large collection of opinions on the Web, some form of summary of opinions is needed (Hu and Liu, 2004).
</p>
</div>
</div>
<div id="outline-container-orgheadline8" class="outline-3">
<h3 id="orgheadline8"><span class="section-number-3">2.2</span> Opinion Defintion</h3>
<div class="outline-text-3" id="text-2-2">
<ul class="org-ul">
<li>Observation: An opinion consists of two key components: a target g and a sentiment s on the target.</li>

<li>Definition (Opinion): An opinion is a quadruple, (g, s, h, t), where g is the opinion (or sentiment) target, s is the sentiment about the target, h is the opinion holder and t is the time when the opinion was expressed.</li>

<li>Definition (entity): An entity e is a product, service, topic, issue, person, organization, or event. It is described with a pair, e: (T, W), where T is a hierarchy of parts, sub-parts, and so on, and W is a set of attributes of e.</li>

<li>Definition (opinion): An opinion is a quintuple, (ei, aij, sijkl, hk, tl), where ei is the name of an entity, aij is an aspect of ei, sijkl is the sentiment on aspect aij of entity ei, hk is the opinion holder, and tl is the time when the opinion is expressed by hk. The sentiment sijkl is positive, negative, or neutral, or expressed with different strength/intensity levels, e.g., 1 to 5 stars as used by most review sits on the Web.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgheadline11" class="outline-2">
<h2 id="orgheadline11"><span class="section-number-2">3</span> Language Technology Processing</h2>
<div class="outline-text-2" id="text-3">
<p>
[<a href="http://ltp.ai/docs/index.html">http://ltp.ai/docs/index.html</a>]
</p>
</div>
<div id="outline-container-orgheadline10" class="outline-3">
<h3 id="orgheadline10"><span class="section-number-3">3.1</span> features:</h3>
<div class="outline-text-3" id="text-3-1">
<ul class="org-ul">
<li>针对单一自然语言处理任务，生成统计机器学习模型的工具</li>
<li>针对单一自然语言处理任务，调用模型进行分析的编程接口</li>
<li>使用流水线方式将各个分析工具结合起来，形成一套统一的中文自然语言处理系统</li>
<li>系统可调用的，用于中文语言处理的模型文件</li>
<li>针对单一自然语言处理任务，基于云端的编程接口</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgheadline18" class="outline-2">
<h2 id="orgheadline18"><span class="section-number-2">4</span> Building the Wikipedia Knowledge Graph in Neo4j</h2>
<div class="outline-text-2" id="text-4">
<ul class="org-ul">
<li>guide:</li>
</ul>
<p>
<a href="http://guides.neo4j.com/wiki">http://guides.neo4j.com/wiki</a>
</p>

<ul class="org-ul">
<li>main topic classification:</li>
</ul>
<p>
<a href="https://en.wikipedia.org/wiki/Category:Main_topic_classifications">https://en.wikipedia.org/wiki/Category:Main_topic_classifications</a>
</p>
</div>
<div id="outline-container-orgheadline12" class="outline-3">
<h3 id="orgheadline12"><span class="section-number-3">4.1</span> Login</h3>
<div class="outline-text-3" id="text-4-1">
<div class="org-src-container">

<pre class="src src-neo4j">:server connect
</pre>
</div>
<div class="org-src-container">

<pre class="src src-text">host:
bolt://ws-10-0-1-111-33640.neo4jsandbox.com:443

username:
neo4j

pwd:
darts-quota-alternation
</pre>
</div>
</div>
</div>

<div id="outline-container-orgheadline13" class="outline-3">
<h3 id="orgheadline13"><span class="section-number-3">4.2</span> Approach 1: Loading a reduced subset incrementally through the MediaWiki API</h3>
<div class="outline-text-3" id="text-4-2">
<ul class="org-ul">
<li>wiki dumps:</li>
</ul>

<p>
<a href="https://jesusbarrasa.wordpress.com/2016/08/03/quickgraph2-how-is-wikipedias-knowledge-organised/">https://jesusbarrasa.wordpress.com/2016/08/03/quickgraph2-how-is-wikipedias-knowledge-organised/</a>
</p>

<p>
<a href="https://jesusbarrasa.wordpress.com/2017/04/26/quickgraph6-building-the-wikipedia-knowledge-graph-in-neo4j-qg2-revisited/">https://jesusbarrasa.wordpress.com/2017/04/26/quickgraph6-building-the-wikipedia-knowledge-graph-in-neo4j-qg2-revisited/</a>
</p>

<p>
<a href="https://github.com/jbarrasa/datasets/blob/master/wikipedia/wiki-guide.adoc">https://github.com/jbarrasa/datasets/blob/master/wikipedia/wiki-guide.adoc</a>
</p>

<ul class="org-ul">
<li>Wiki API JSON format:</li>
</ul>
<p>
<a href="https://www.mediawiki.org/wiki/API:Categorymembers">https://www.mediawiki.org/wiki/API:Categorymembers</a>
</p>
<div class="org-src-container">

<pre class="src src-json">{
    "batchcomplete": "",
    "continue": {
        "cmcontinue": "page|2b273f2f3d29272b3b0445434d2f414d37273d0117018f16|55503653",
        "continue": "-||"
    },
    "query": {
        "categorymembers": [
            {
                "pageid": 22939,
                "ns": 0,
                "title": "Physics"
            },
            {
                "pageid": 3445246,
                "ns": 0,
                "title": "Glossary of classical physics"
            },
            {
                "pageid": 24489,
                "ns": 0,
                "title": "Outline of physics"
            },
            {
                "pageid": 1653925,
                "ns": 100,
                "title": "Portal:Physics"
            },
            {
                "pageid": 50926902,
                "ns": 0,
                "title": "Action angle coordinates"
            },
            {
                "pageid": 9079863,
                "ns": 0,
                "title": "Aerometer"
            },
            {
                "pageid": 52657328,
                "ns": 0,
                "title": "Bayesian model of computational anatomy"
            },
            {
                "pageid": 49342572,
                "ns": 0,
                "title": "Group actions in computational anatomy"
            },
            {
                "pageid": 50724262,
                "ns": 0,
                "title": "Blasius\u2013Chaplygin formula"
            },
            {
                "pageid": 33327002,
                "ns": 0,
                "title": "Cabbeling"
            }
        ]
    }
}
</pre>
</div>

<ul class="org-ul">
<li>Clause of building wikipedia graph</li>
</ul>
<div class="org-src-container">

<pre class="src src-neo4j">//Loading the data into Neo4j
//prepare the DB with a few indexes to accelerate the ingestion and querying of the data:
CREATE INDEX ON :Category(catId)
CREATE INDEX ON :Category(catName)
CREATE INDEX ON :Page(pageTitle)

//Loading a reduced subset incrementally through the MediaWiki API
//create the Wikipedia Knowledge Graph about Databases.
//create the root category: Databases.
CREATE (c:Category:RootCategory {catId: 0, catName: 'Databases', subcatsFetched : false, pagesFetched : false, level: 0 })

//iteratively load the next level of subcategories to a depth of our choice.
UNWIND range(0,3) as level
CALL apoc.cypher.doIt("
MATCH (c:Category { subcatsFetched: false, level: $level})
CALL apoc.load.json('https://en.wikipedia.org/w/api.php?format=json&amp;action=query&amp;list=categorymembers&amp;cmtype=subcat&amp;cmtitle=Category apoc.text.urlencode(c.catName) + '&amp;cmprop=ids%7Ctitle&amp;cmlimit=500')
YIELD value as results
UNWIND results.query.categorymembers AS subcat
MERGE (sc:Category {catId: subcat.pageid})
ON CREATE SET sc.catName = substring(subcat.title,9),
 sc.subcatsFetched = false,
 sc.pagesFetched = false,
 sc.level = $level + 1
WITH sc,c
CALL apoc.create.addLabels(sc,['Level' + ($level + 1) + 'Category']) YIELD node
MERGE (sc)-[:SUBCAT_OF]-&gt;(c)
WITH DISTINCT c
SET c.subcatsFetched = true", { level: level }) YIELD value
RETURN value
//load the pages in a similar way
UNWIND range(0,4) as level
CALL apoc.cypher.doIt("
MATCH (c:Category { pagesFetched: false, level: $level })
CALL apoc.load.json('https://en.wikipedia.org/w/api.php?format=json&amp;action=query&amp;list=categorymembers&amp;cmtype=page&amp;cmtitle=Category apoc.text.urlencode(c.catName) + '&amp;cmprop=ids%7Ctitle&amp;cmlimit=500')
YIELD value as results
UNWIND results.query.categorymembers AS page
MERGE (p:Page {pageId: page.pageid})
ON CREATE SET p.pageTitle = page.title, p.pageUrl = 'http://en.wikipedia.org/wiki/' + apoc.text.urlencode(replace(page.title, ' ', '_'))
WITH p,c
MERGE (p)-[:IN_CATEGORY]-&gt;(c)
WITH DISTINCT c
SET c.pagesFetched = true", { level: level }) yield value
return value
</pre>
</div>
</div>
</div>
<div id="outline-container-orgheadline17" class="outline-3">
<h3 id="orgheadline17"><span class="section-number-3">4.3</span> Approach 2: Batch loading the data with LOAD CSV from an SQL dump</h3>
<div class="outline-text-3" id="text-4-3">
<ul class="org-ul">
<li>basics</li>
<li>wiki page structure example:</li>
</ul>
<p>
<a href="https://en.wikipedia.org/wiki/Category:Graph_databases">https://en.wikipedia.org/wiki/Category:Graph_databases</a>
</p>

<p>
Category:Graph databases
From Wikipedia, the free encyclopedia
</p>

<p>
Subcategories
This category has only the following subcategory.
R
► Resource Description Framework‎ (5 C, 24 P)
</p>

<p>
Pages in category "Graph databases"
The following 15 pages are in this category, out of 15 total. This list may not reflect recent changes (learn more).
</p>

<p>
Graph database
A
AllegroGraph
ArangoDB
C
Cypher Query Language
D
DataStax
Sparksee (graph database)
F
FlockDB
G
GRAKN.AI
I
InfiniteGraph
L
Linkurious
M
Mulgara (software)
N
Neo4j
O
Oracle Spatial and Graph
OrientDB
S
Sones GraphDB
</p>

<p>
Categories: Types of databasesGraph theory
</p>

<ul class="org-ul">
<li>category content sample:</li>
</ul>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">category id</td>
<td class="org-left">auto incremental index</td>
<td class="org-left">category name</td>
<td class="org-left">page count</td>
<td class="org-left">sub-category count</td>
</tr>

<tr>
<td class="org-left">"895945",</td>
<td class="org-left">"3",</td>
<td class="org-left">"Computer_storage_devices",</td>
<td class="org-left">"86",</td>
<td class="org-left">"10"</td>
</tr>
</tbody>
</table>

<ul class="org-ul">
<li>relation sample:</li>
</ul>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">from category</td>
<td class="org-left">to category(supercategory)</td>
</tr>

<tr>
<td class="org-left">"28169972",</td>
<td class="org-left">"51326333"</td>
</tr>
</tbody>
</table>

<ul class="org-ul">
<li>import csv to neo4j</li>
</ul>
<div class="org-src-container">

<pre class="src src-cypher">USING PERIODIC COMMIT 10000
LOAD CSV FROM "https://github.com/jbarrasa/datasets/blob/master/wikipedia/data/cats.csv?raw=true" as row
CREATE (c:Category { catId: row[0]})
SET c.catName = row[2], c.pageCount = toInt(row[3]), c.subcatCount = toInt(row[4])

USING PERIODIC COMMIT 10000
LOAD CSV FROM "https://github.com/jbarrasa/datasets/blob/master/wikipedia/data/rels.csv?raw=true" as row
MATCH (from:Category { catId: row[0]})
MATCH (to:Category { catId: row[1]})
CREATE (from)-[:SUBCAT_OF]-&gt;(to)
</pre>
</div>

<ul class="org-ul">
<li>regenerating fresh csv files:</li>
<li>Start by downloading the latest DB dumps from the Wikipedia downloads page.</li>
<li>For the category hierarchy, you’ll only need the following tables: category, categorylinks and page.</li>
<li>Load them in your DBMS.</li>
<li>Generate the categories CSV file by running the following SQL.</li>
</ul>
<div class="org-src-container">

<pre class="src src-sql"><span style="color: #F92672;">select</span> p.page_id <span style="color: #F92672;">as</span> PAGE_ID, c.cat_id <span style="color: #F92672;">as</span> CAT_ID, <span style="color: #F92672;">cast</span><span style="color: #AE81FF;">(</span>c.cat_title <span style="color: #F92672;">as</span> <span style="color: #66D9EF;">nCHAR</span><span style="color: #AE81FF;">)</span> <span style="color: #F92672;">as</span> CAT_TITLE , c.cat_pages <span style="color: #F92672;">as</span> CAT_PAGES_COUNT, c.cat_subcats <span style="color: #F92672;">as</span> CAT_SUBCAT_COUNT
<span style="color: #F92672;">into</span> outfile <span style="color: #E6DB74;">'/Users/jbarrasa/Applications/neo4j-enterprise-3.1.2/import/wiki/cats.csv'</span> fields terminated <span style="color: #F92672;">by</span> <span style="color: #E6DB74;">','</span> enclosed <span style="color: #F92672;">by</span> <span style="color: #E6DB74;">'"'</span> escaped <span style="color: #F92672;">by</span> <span style="color: #E6DB74;">'\\'</span> lines terminated <span style="color: #F92672;">by</span> <span style="color: #E6DB74;">'\n'</span>
<span style="color: #F92672;">from</span> test.category c, test.page p
<span style="color: #F92672;">where</span> c.cat_title = p.page_title
<span style="color: #F92672;">and</span> p.page_namespace = <span style="color: #AE81FF;">14</span>
</pre>
</div>
<ol class="org-ol">
<li>Generate the relationships file by running the following SQL</li>
</ol>
<div class="org-src-container">

<pre class="src src-sql"><span style="color: #F92672;">select</span> p.page_id <span style="color: #F92672;">as</span> FROM_PAGE_ID, p2.page_id <span style="color: #F92672;">as</span> TO_PAGE_ID
<span style="color: #F92672;">into</span> outfile <span style="color: #E6DB74;">'/Users/jbarrasa/Applications/neo4j-enterprise-3.1.2/import/wiki/rels.csv'</span> fields terminated <span style="color: #F92672;">by</span> <span style="color: #E6DB74;">','</span> enclosed <span style="color: #F92672;">by</span> <span style="color: #E6DB74;">'"'</span> escaped <span style="color: #F92672;">by</span> <span style="color: #E6DB74;">'\\'</span> lines terminated <span style="color: #F92672;">by</span> <span style="color: #E6DB74;">'\n'</span>
<span style="color: #F92672;">from</span> test.category c, test.page p , test.categorylinks l, test.category c2, test.page p2
<span style="color: #F92672;">where</span> l.cl_type = <span style="color: #E6DB74;">'subcat'</span>
<span style="color: #F92672;">and</span> c.cat_title = p.page_title
<span style="color: #F92672;">and</span> p.page_namespace = <span style="color: #AE81FF;">14</span>
<span style="color: #F92672;">and</span> l.cl_from = p.page_id
<span style="color: #F92672;">and</span> l.cl_to = c2.cat_title
<span style="color: #F92672;">and</span> c2.cat_title = p2.cat_title
<span style="color: #F92672;">and</span> p2.page_namespace = <span style="color: #AE81FF;">14</span>
</pre>
</div>
</div>

<div id="outline-container-orgheadline16" class="outline-4">
<h4 id="orgheadline16"><span class="section-number-4">4.3.1</span> Data dumps/Import</h4>
<div class="outline-text-4" id="text-4-3-1">
</div><ol class="org-ol"><li><a id="orgheadline14"></a>structure:<br  /><div class="outline-text-5" id="text-4-3-1-1">
<ul class="org-ul">
<li>category:</li>
</ul>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<tbody>
<tr>
<td class="org-right">cat_id</td>
<td class="org-left">cat_title</td>
<td class="org-right">cat_pages</td>
<td class="org-right">cat_subcats</td>
<td class="org-right">cat_files</td>
</tr>

<tr>
<td class="org-right">3</td>
<td class="org-left">'Computer_storage_devices'</td>
<td class="org-right">88</td>
<td class="org-right">10</td>
<td class="org-right">0</td>
</tr>
</tbody>
</table>

<ul class="org-ul">
<li>category links:</li>
</ul>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-right">cl_from</td>
<td class="org-left">cl_to</td>
<td class="org-left">cl_sortke</td>
<td class="org-left">cl_timestamp</td>
<td class="org-left">cl_sortkey_prefix</td>
<td class="org-left">cl_collation</td>
<td class="org-left">cl_type('page','subcat','file')</td>
</tr>

<tr>
<td class="org-right">55706942</td>
<td class="org-left">'NA-importance_NA-Class_Russia_articles'</td>
<td class="org-left">'^R&lt;82&gt;,&lt;BF&gt;^DIOKK7\'A^D+CAKM7MOM7CA\'=^D+I7K7K^A#^A&lt;84&gt;&lt;8F&gt; '</td>
<td class="org-left">'2017-11-04 07:25:01'</td>
<td class="org-left">'Adonis, Rochelle'</td>
<td class="org-left">'uca-default-u-kn'</td>
<td class="org-left">'page'</td>
</tr>
</tbody>
</table>

<ul class="org-ul">
<li>pages:</li>
</ul>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">page_id</td>
<td class="org-left">page_namespace</td>
<td class="org-left">page_title</td>
<td class="org-left">page_restrictions</td>
<td class="org-left">page_counter</td>
<td class="org-left">page_is_redirect</td>
<td class="org-left">page_is_new</td>
<td class="org-left">page_random</td>
<td class="org-left">page_touched</td>
<td class="org-left">page_links_updated</td>
<td class="org-left">page_latest</td>
<td class="org-left">page_len</td>
<td class="org-left">page_content_model</td>
<td class="org-left">page_lang</td>
</tr>

<tr>
<td class="org-left">'10'</td>
<td class="org-left">'0'</td>
<td class="org-left">'AccessibleComputing'</td>
<td class="org-left">?</td>
<td class="org-left">'0'</td>
<td class="org-left">'1'</td>
<td class="org-left">'0'</td>
<td class="org-left">'0.33167112649574004'</td>
<td class="org-left">'20171002144257'</td>
<td class="org-left">'20171003005845'</td>
<td class="org-left">'767284433'</td>
<td class="org-left">'124'</td>
<td class="org-left">'wikitext'</td>
<td class="org-left">NULL</td>
</tr>
</tbody>
</table>

<ul class="org-ul">
<li>page links:</li>
</ul>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />

<col  class="org-left" />

<col  class="org-right" />
</colgroup>
<tbody>
<tr>
<td class="org-right">pl_from</td>
<td class="org-right">pl_namespace</td>
<td class="org-left">pl_title</td>
<td class="org-right">pl_from_namespace</td>
</tr>

<tr>
<td class="org-right">42886934</td>
<td class="org-right">0</td>
<td class="org-left">'!Women_Art_Revolution'</td>
<td class="org-right">0</td>
</tr>
</tbody>
</table>
</div></li>

<li><a id="orgheadline15"></a>methods<br  /><div class="outline-text-5" id="text-4-3-1-2">
<p>
<a href="https://meta.wikimedia.org/wiki/Data_dumps">https://meta.wikimedia.org/wiki/Data_dumps</a>
</p>

<p>
<a href="https://meta.wikimedia.org/wiki/Data_dumps/Import_examples">https://meta.wikimedia.org/wiki/Data_dumps/Import_examples</a>
</p>

<p>
<a href="https://phabricator.wikimedia.org/source/operations-dumps-import-tools/browse/master/xmlfileutils/">https://phabricator.wikimedia.org/source/operations-dumps-import-tools/browse/master/xmlfileutils/</a>
</p>
<ul class="org-ul">
<li>tools</li>
</ul>
<p>
<a href="http://wikipapers.referata.com/wiki/List_of_visualization_tools">http://wikipapers.referata.com/wiki/List_of_visualization_tools</a>
</p>

<ul class="org-ul">
<li>Import into an empty wiki of el wiktionary on Linux with MySQL[edit]</li>
</ul>
<p>
MediaWiki version: 1.20
</p>

<p>
This wiki was chosen because it uses a non-latin1 character set, has a reasonable number of articles but isn't huge, and relies on only a small number of extensions.
</p>

<p>
I chose to import only the current pages, with User or Talk pages, because most folks who set up local mirrors want the article content and not the revision history or the discussion pages.
</p>

<p>
Before the import[edit]
I downloaded the dumps for a given day. I got all the sql.gz files, the stub-articles.xml.gz file, and the pages-articles.xml.bz2 file from <a href="http://download.wikimedia.org/elwiktionary/">http://download.wikimedia.org/elwiktionary/</a> even though I knew there would be a few of those sql files I wouldn't need.
I installed the prerequisites for MediaWiki, including MySQL, PHP 5, Apache, php-mysql, php-intl, ImageMagick and rsvg (see the manual).
I downloaded MediaWiki 1.20 and unpacked it into /var/www/html/elwikt (your location may vary).
I installed MediaWiki 1.20 on my laptop, with the following settings:
el for my language and the wiki language
MySQL database type
localhost for hostname (hey, it's a local install on my laptop :-P)
elwikt for database name
no database table prefix
root db username and password for the database username and password for install
a different user name and password for the database account for web access, with 'create if it does not exist' checked
InnoDB table format
Binary character set
Disable media uploads
use InstantCommons
I selected the extensions I wanted installed via the installer, some of them not being necessary but I thought they would be useful to have if I did decide to locally edit:
ConfirmEdit
Gadgets
Nuke
ParserFunctions
RenameUser
Vector
WikiEditor
I generated page, revision and text sql files from the stub and page content XML files, using mwxml2sql via the command mwxml2sql -s elwiktionary-blahblah-stub-articles.xml.gz -t elwiktionary-blahblah-pages-articles.xml.bz2 -f elwikt-pages-current-sql.gz -m 1.20
I converted all the sql files to tab delimited files using sql2txt (same repo as previous step) via the command zcat elwiktionary-blahdate-blahtable.sql.gz | sql2txt | gzip &gt; elwiktionary-blahdate-blahtable.tabs.gz. Actually that's a lie, I wrote a tiny bash script to do them all for me. I skipped the following downloaded files:
site_stats - I didn't want or need these, the numbers would be wrong anyways
user_groups - Not needed for displaying page content
old_image and image - using InstantCommons
page - generated from XML files instead
I converted the page, revision and text table files that were generated from the XML files, to tab delimited, using a command similar to the above step
The actual import[edit]
Note: maybe using charset 'binary' here would be better!
</p>

<p>
I imported all of the above files into MySQL, doing the following:
</p>
<div class="org-src-container">

<pre class="src src-sql">mysql -u root -p
mysql&gt;use elwikt
mysql&gt;<span style="color: #F92672;">SET</span> autocommit=<span style="color: #AE81FF;">0</span>;
mysql&gt;<span style="color: #F92672;">SET</span> foreign_key_checks=<span style="color: #AE81FF;">0</span>;
mysql&gt;<span style="color: #F92672;">SET</span> unique_checks=<span style="color: #AE81FF;">0</span>;
mysql&gt;<span style="color: #F92672;">SET</span> character_set_client = utf8;
# unpacked the tab delimited file
mysql&gt;TRUNCATE <span style="color: #F92672;">TABLE</span> tablenamehere;
mysql&gt;LOAD <span style="color: #F92672;">DATA</span> INFILE <span style="color: #F92672;">path</span>-<span style="color: #F92672;">to</span>-tab-delim-file-<span style="color: #F92672;">for</span>-<span style="color: #F92672;">table</span>-here FIELDS OPTIONALLY ENCLOSED <span style="color: #F92672;">BY</span> <span style="color: #E6DB74;">'\'';</span>
<span style="color: #E6DB74;">repeated this for all tab delim files</span>
<span style="color: #E6DB74;">mysql&gt;exit;</span>

<span style="color: #E6DB74;"># or https://meta.wikimedia.org/wiki/Data_dumps/Import_examples/catswiki_bash_script</span>
<span style="color: #E6DB74;">echo "TRUNCATE TABLE $table ; " | mysql -u root -pnotverysecure enwiki</span>
<span style="color: #E6DB74;">mysql -u root -pnotverysecure enwiki</span>
</pre>
</div>
<p>
After the import[edit]
Since this is a wiktionary, I updated the LocalSettings.php file so that page titles need not start with a capital letter, adding $wgCapitalLinks = false; to the file
Since this wiki has extra namespaces beyond the standard ones defined by MediaWiki, I added those to LocalSettings.php. You can find such namespaces by looking at the first few lines of the stubs XML file. Lines added: $wgExtraNamespaces = 'Παράρτημα'; and $wgExtraNamespaces = 'Συζήτηση_παραρτήματος';.
The namespace for the project and for project discussion are typically special localized names. I added those to LocalSettings.php, finding the names in the stub XML file at the beginning: $wgMetaNamespace = 'Βικιλεξικό'; and $wgMetaNamespaceTalk = 'Συζήτηση_βικιλεξικού';
I installed tidy and added the following lines to LocalSettings.php to reflect that: $wgUseTidy = true; and $wgTidyBin = '/usr/bin/tidy';. No configuration file was necessary; one is provided as part of MediaWiki and used by default.
I set up the interwiki cache cdb file, by using fixup-interwikis.py via the command python fixup-interwikis.py &#x2013;localsettings /var/www/html/elwikt/LocalSettings.php &#x2013;sitetype wiktionary and then added $wgInterwikiCache = "$IP/cache/interwiki.cdb" to the LocalSettings.php file. (See mw:Interwiki_cache/Setup_for_your_own_wiki for info.)
That was it. This was enough to let me view (most) pages without errors.
</p>
</div></li></ol>
</div>
</div>
</div>

<div id="outline-container-orgheadline21" class="outline-2">
<h2 id="orgheadline21"><span class="section-number-2">5</span> TensorBoard: Embedding Visualization</h2>
<div class="outline-text-2" id="text-5">
</div><div id="outline-container-orgheadline19" class="outline-3">
<h3 id="orgheadline19"><span class="section-number-3">5.1</span> Load data</h3>
<div class="outline-text-3" id="text-5-1">
<p>
Step 1: Load a TSV file of vectors.
Example of 3 vectors with dimension 4:
0.1\t0.2\t0.5\t0.9
0.2\t0.1\t5.0\t0.2
0.4\t0.1\t7.0\t0.8
</p>


<p>
Step 2 (optional): Load a TSV file of metadata.
Example of 3 data points and 2 columns.
Note: If there is more than one column, the first row will be parsed as column labels.
Pokémon\tSpecies
Wartortle\tTurtle
Venusaur\tSeed
Charmeleon\tFlame
</p>
</div>
</div>

<div id="outline-container-orgheadline20" class="outline-3">
<h3 id="orgheadline20"><span class="section-number-3">5.2</span> Projections</h3>
<div class="outline-text-3" id="text-5-2">
<p>
The Embedding Projector has three methods of reducing the dimensionality of a data set: two linear and one nonlinear. Each method can be used to create either a two- or three-dimensional view.
</p>

<ul class="org-ul">
<li><a href="http://setosa.io/ev/principal-component-analysis/">Principal Component Analysis</a></li>
</ul>
<p>
A straightforward technique for reducing dimensions is Principal Component Analysis (PCA). The Embedding Projector computes the top 10 principal components. The menu lets you project those components onto any combination of two or three. PCA is a linear projection, often effective at examining global geometry.
</p>

<ul class="org-ul">
<li><a href="https://distill.pub/2016/misread-tsne/">t-SNE</a></li>
</ul>
<p>
A popular non-linear dimensionality reduction technique is t-SNE. The Embedding Projector offers both two- and three-dimensional t-SNE views. Layout is performed client-side animating every step of the algorithm. Because t-SNE often preserves some local structure, it is useful for exploring local neighborhoods and finding clusters. Although extremely useful for visualizing high-dimensional data, t-SNE plots can sometimes be mysterious or misleading. See this great article for how to use t-SNE effectively.
</p>
</div>
</div>
</div>
</div>
</body>
</html>
