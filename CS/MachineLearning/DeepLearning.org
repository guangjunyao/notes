#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline author:t c:nil
#+OPTIONS: creator:nil d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t
#+OPTIONS: num:t p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t timestamp:t
#+OPTIONS: title:t toc:t todo:t |:t
#+TITLES: DeepLearning
#+DATE: <2017-10-29 Sun>
#+AUTHORS: weiwu
#+EMAIL: victor.wuv@gmail.com
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 24.5.1 (Org mode 8.3.4)
#+SETUPFILE: ../../configOrg/level2.org
#+HTML: <div class="outline-2" id="meta">
| *Author* | {{{author}}} ({{{email}}})    |
| *Date*   | {{{time(%Y-%m-%d %H:%M:%S)}}} |
| *Title*  | {{{TITLE}}}                   |
#+HTML: </div>

* Basic prerequisites
[[https://docs.google.com/document/d/1NitqVZyU1zZYRUQmj-0c2Pq3qso7jcbF9XekZlC-w04/edit]]

** maximum likelihood estimation
- Summary
Maximum likelihood is a general and powerful technique for learning statistical models, i.e. fitting the parameters to data. The maximum likelihood parameters are the ones under which the observed data has the highest probability. It is widely used in practice, and techniques such as Bayesian parameter estimation are closely related to maximum likelihood.
- Context
This concept has the prerequisites:
 - random variables
 - independent random variables (The data are generally assumed to be independent draws from a distribution.)
 - optimization problems (Maximum likelihood is formulated as an optimization problem.)
 - Gaussian distribution (Fitting a Gaussian distribution is an instructive example of maximum likelihood estimation.)
** terminology/jargon:
#+INCLUDE: glossary.org
[[file:glossary.org]]
- tensor
A tensor consists of a set of primitive values shaped into an array of any number of dimensions. A tensor's rank is its number of dimensions. Here are some examples of tensors:
#+BEGIN_SRC python
3 # a rank 0 tensor; a scalar with shape []
[1., 2., 3.] # a rank 1 tensor; a vector with shape [3]
[[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3]
[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]
#+END_SRC
a mathematical object analogous to but more general than a vector, represented by an array of components that are functions of the coordinates of a space.
- synapse
突触,activation/link layer.
* 深度学习

深度学习（英语：deep learning）是机器学习拉出的分支，*它试图使用包含复杂结构或由多重非线性变换构成的多个处理层对数据进行高层抽象的算法*.
深度学习是机器学习中一种基于对数据进行表征学习的方法。观测值（例如一幅图像）可以使用多种方式来表示，如每个像素强度值的向量，或者更抽象地表示成一系列边、特定形状的区域等。而使用某些特定的表示方法更容易从实例中学习任务（例如，人脸识别或面部表情识别）。深度学习的好处是用非监督式或半监督式的特征学习和分层特征提取高效算法来替代手工获取特征。
表征学习的目标是寻求更好的表示方法并创建更好的模型来从大规模未标记数据中学习这些表示方法。表达方式类似神经科学的进步，并松散地创建在类似神经系统中的信息处理和通信模式的理解上，如神经编码，试图定义拉动神经元的反应之间的关系以及大脑中的神经元的电活动之间的关系。
** Definitions
Deep learning is a class of machine learning algorithms that:
- use a cascade of multiple layers of nonlinear processing units for feature extraction and transformation. Each successive layer uses the output from the previous layer as input.
- learn in supervised (e.g., classification) and/or unsupervised (e.g., pattern analysis, 人脸识别或面部表情识别) manners.
- learn multiple levels of representations that correspond to different levels of abstraction; the levels form a hierarchy of concepts.
- use some form of gradient descent for training via backpropagation.
Layers that have been used in deep learning include hidden layers of an artificial neural network and sets of propositional formulas.
** why deep?
There are functions you can compute with a small L-layer deep neural network that shallower networks require exponentially more hidden units to compute.

For example,
$$y=X_1 XOR X_2 XOR X_3 XOR ... XOR X_n$$
for deep neural networks with less hidden units, the computation is O(log(n)). But for shallower neural networks, the computation is O(2^n).

* 学习方法
- Step 1: 学习机器学习基础
- Step 2: 深入学习
- Step 3: 选择一个区域并进一步深入
  - 计算机视觉(Computer Vision):
  - 自然语言处理(NLP)：
  - 记忆网络(RNN-LSTM)
  - 深度加强学习(RDL):
  - 生成模型(GAN):
- Step 4: 建立项目
* NLP
[[file:./NaturalLanguageProcessing.org][NLP]]
** Application: Where can DL be applied for NLP tasks? DL Algorithms NLP Usage Neural Network (NN)
*** Feed-forward propagation
- POS, NER, Chunking
- Entity and Intent Extraction
*** Recurrent Neural Networks (RNN)
- Language Modeling and Generating Text
- Machine Translation
- Question Answering System
- Image Captioning
- Generating Image Descriptions
*** Recursive Neural Networks
- Parsing Sentences
- Sentiment Analysis
- Paraphrase Detection
- Relation Classification
- Object Detection
*** Convolutional Neural Network (CNN)
- Sentence / Text Classification
- Relation Extraction and Classification
- Sentiment classification
- Spam Detection or Topic Categorization
- Classification of Search Queries
- Semantic relation extraction
* Critical questions
how - overview picture
why - assumption, hypothesis(formulas), representations, why use this, why does it work, cons, 边界.
example
comparison
results
conclusion
*** 传统机器学习考察点：
1、bias与variance的含义，并结合ensemble method问哪种方法降低bias，哪种方法降低variance
https://machinelearningmastery.com/gentle-introduction-to-the-bias-variance-trade-off-in-machine-learning/
2、lr与svm的区别与联系
SVM：非概率二元线性分类器，利用核方法，有效进行非线性分类。Try to maximize the margin between the closest support vectors geometrically. Instead of assuming a probabilistic model, we're trying to find a particular optimal separating hyperplane, where we define "optimality" in the context of the support vectors.

LR：Logistic regression measures the relationship between the categorical dependent variable and one or more independent variables *by estimating probabilities using a logistic function*, which is the cumulative logistic distribution.
#+CAPTION: lr vs svm
[[./Images/lr_vs_svm.jpg]]
3、gbdt与adaboost的区别与联系

4、手推svm，svm麻雀虽小五脏俱全

5、pca与lda的区别与联系，并推导


6、白化的原理与作用

7、给一个算法，例如lr，问这个算法的model、evaluate、optimization分别是啥

- 回归模型中存在多重共线性, 你如何解决这个问题？
我们可以先去除一个共线性变量; 计算VIF(方差膨胀因子), 采取相应措施;为了避免损失信息, 我们可以使用一些正则化方法, 比如, 岭回归和lasso回归.

*** 深度学习考察点：
- Nodes of output layer depend on the number of categories?
If there are many categories, weight matrix will be very large. Here we use hierarchical softmax to control the classes falling in (0, 1).

- NN loss function
[[./Images/cost_function.png]]
$$J(θ)=∑(y(i)−(1+e−θTx(i))−1)2$$
$$min J(\Theta)$$
need code to compute:
$$-J(\Theta)$$
$$-\frac{ }{\partial \Theta_{ij}^{(l)}} J(\Theta)$$
1、手推bp

2、梯度消失/爆炸原因，以及解决方法
随着神经网络层数的加深，优化函数越来越容易陷入局部最优解，并且这个“陷阱”越来越偏离真正的全局最优。

随着网络层数增加，“梯度消失”现象更加严重。具体来说，我们常常使用sigmoid作为神经元的输入输出函数。对于幅度为1的信号，在BP反向传播梯度时，每传递一层，梯度衰减为原来的0.25。层数一多，梯度指数衰减后低层基本上接受不到有效的训练信号。

Hinton利用预训练方法缓解了局部最优解问题，为了克服梯度消失，ReLU、maxout等传输函数代替了sigmoid，形成了如今DNN的基本形式。去年出现的高速公路网络(highway network)和深度残差学习（deep residual learning）进一步避免了梯度消失，网络层数达到了前所未有的一百多层（深度残差学习：152层）

全连接DNN的结构里下层神经元和所有上层神经元都能够形成连接，带来的潜在问题是参数数量的膨胀。假设输入的是一幅像素为1K*1K的图像，隐含层有1M个节点，光这一层就有10^12个权重需要训练，这不仅容易过拟合，而且极容易陷入局部最优。


3、bn的原理，与白化的联系
[[http://blog.csdn.net/fate_fjh/article/details/53375881]]
Batch Normalization是由google提出的一种训练优化方法。参考论文：Batch Normalization Accelerating Deep Network Training by Reducing Internal Covariate Shift[1]
个人觉得BN层的作用是加快网络学习速率，论文中提及其它的优点都是这个优点的副产品。
网上对BN解释详细的不多，大多从原理上解释，没有说出实际使用的过程，这里从what, why, how三个角度去解释BN。

- What is BN

Normalization是数据标准化（归一化，规范化），Batch 可以理解为批量，加起来就是批量标准化。

- Why is BN

解决的问题是梯度消失与梯度爆炸。

关于梯度消失，以sigmoid函数为例子，sigmoid函数使得输出在[0,1]之间。

事实上x到了一定大小，经过sigmoid函数的输出范围就很小了.

如果输入很大，其对应的斜率就很小，我们知道，其斜率（梯度）在反向传播中是权值学习速率。所以就会出现如下的问题，
在深度网络中，如果网络的激活输出很大，其梯度就很小，学习速率就很慢。假设每层学习梯度都小于最大值0.25，网络有n层，因为链式求导的原因，第一层的梯度小于0.25的n次方，所以学习速率就慢，对于最后一层只需对自身求导1次，梯度就大，学习速率就快。
这会造成的影响是在一个很大的深度网络中，浅层基本不学习，权值变化小，后面几层一直在学习，结果就是，后面几层基本可以表示整个网络，失去了深度的意义。

关于梯度爆炸，根据链式求导法，
第一层偏移量的梯度=激活层斜率1x权值1x激活层斜率2x…激活层斜率(n-1)x权值(n-1)x激活层斜率n
假如激活层斜率均为最大值0.25，所有层的权值为100，这样梯度就会指数增加

-How to use BN

4、防止过拟合有哪些方法(regularization):
- weight decay:

$$J(W)= MSE_{train}+\lambda\omega^T\omega$$
where $\lambda$ is a value chosen ahead of time that controls the strength of our preference for smaller weights. When $\lambda=0$, we impose no preference, and larger$\lambda$ forces the weights to become smaller. Minimizing J(w) results in a choice of weights that make a tradeoff between fitting the training data and being small.


To get the optimized $\lambda$, splitting data set to train set and validation set.
$$\lambda={10^{-2}, 10^{-1.5}, 10^{-1}, ..., 10, 10^{1.5}, 10^{2}}$$

- restrict parameter values
putting extra constraints on models such as adding restrictions on the parameter values.

- soft constraint
add extra terms in the objective function that can be thought of as corresponding to a soft constraint on the parameter values.

5、dnn、cnn、rnn的区别与联系
DNN是一个大类，CNN是一个典型的空间上深度的神经网络，RNN是在时间上深度的神经网络。

为了克服梯度消失，ReLU、maxout等传输函数代替了sigmoid，形成了如今DNN的基本形式.

图像中有固有的局部模式（比如轮廓、边界，人的眼睛、鼻子、嘴等）可以利用，显然应该将图像处理中的概念和神经网络技术相结合。此时我们可以祭出题主所说的卷积神经网络CNN。对于CNN来说，并不是所有上下层神经元都能直接相连，而是通过“卷积核”作为中介。同一个卷积核在所有图像内是共享的，图像通过卷积操作后仍然保留原先的位置关系。

样本出现的时间顺序对于自然语言处理、语音识别、手写体识别等应用非常重要。对了适应这种需求，就出现了大家所说的另一种神经网络结构——循环神经网络RNN。


6、机器学习与深度学习的联系

7、batch size大小会怎么影响收敛速度

*** 最优化考察点：
1、sgd、momentum、rmsprop、adam区别与联系

2、深度学习为什么不用二阶优化

3、拉格朗日乘子法、对偶问题、kkt条件

- coding考察点： 排序、双指针、dp、贪心、分治、递归、回溯、字符串、树、链表、trie、bfs、dfs等等

- 第一种是广撒网地问一些老生常谈的DL中没有标准答案的问题，比如过拟合怎么办？样本偏斜怎么办？
drop out，data augmentation， weight decay(常用的weight decay有哪些？怎么处理weight decay的权重).L1，L2。让你比较为什么要两种weight decay，区别在哪里。比如如果你讲L1零点不可导才用L2，那么立马问你SMOOTHL1。如果你都说明白了，就问你为什么weight decay能够一定程度解决过拟合？如果你说到了L0和稀疏性。接着就来问你为什么稀疏性有效？

用Map Reduce implement矩阵乘法
NLP相关的encoding问题 (CBOW vs Skipgram)
不同的activation function的pros/cons
Gradient Boosting相关问题
Random Forest 相关问题
SVM的Gaussian Kernel 的 dimension
用Regex分析文本
如何用python/R 读取JSON, 并且洗数据
用C++ implement Monte Carlo
coding: 用DFS走迷宫

用过哪些DL的library呀?
现在的DL 的state of art model有哪些呀?
如果如理diminishing gradient的问题呀?
如果同时处理文本文档+图片呀?
如果防止overfitting呀?
如何pre-train model呀?
能否自己在服务器上用distributed computing部署一个现有的model 呀?

解决网络过拟合的手段有些什么呀
Dropout的为什么可以解决过拟合呀
Batch-normalization的思想是什么呀
类别不平衡的时候怎么办啊
目标检测中anchor box的做法和adaboost人脸检测中的滑窗检测有什么区别啊？
跟踪和检测有什么区别啊？
- 用过几个框架？
https://deeplearning4j.org/cn/compare-dl4j-torch7-pylearn#tensorflow
 - Lua
 Torch 和 Pytorch

 - Python 框架
 Theano及其生态系统, TensorFlow, Caffe, Caffe2, CNTK, Chainer, DSSTNE, DyNet, Keras, Paddle, 它们的优劣分析一下.
*** 我们在这里将机器学习工程师需要掌握的基本技能分为五类：



1	计算机科学基础与编程能力
2	概率与统计
3	数据建模与评估
4	应用机器学习算法与库
5	软件工程和系统设计


（一）计算机科学基础与编程能力


▲ 你怎么判断一个链表中是否有循环？

▲ 给定一棵二叉查找树中的两个元素，求它们的最近公共祖先。

▲ 写一个栈排列函数

▲ 如何计算比较排序算法的时间复杂度？你能证明吗？

▲ 如何在加权图中找到两个节点间最短路径？如果有些权值是负的怎么办？

▲ 求一个字符串中所有的回文子串。



对于所有这些问题，你都要能够推导出你的方法的时间和空间复杂度，并且尽可能用最低复杂度解决问题。


只有通过大量的练习才能对这些不同类型的问题烂熟于胸，这样你就能够在面试时快速给出一个有效的解决方案。


常用的算法面试准备平台有 Lintcode、LeetCode、Interview Cake等。



（二）概率与统计


▲ 给出一个群体中男性和女性各自的平均身高，整个群体的平均身高是多少？

▲ 最近一项调查显示，在意大利1/3的汽车是费拉里斯（法拉利跑车），这其中一半的车都是红色。那么如果你在意大利的街头看到一辆红色的汽车驶来，请问它是费拉里斯的可能性有多大？

▲ 你想在网站上找到一个最合适的位置放广告，你可以选择广告字体的大小(小号、中号、大号)，你也可以选择广告放置的位置(顶部、中部、底部)。那么至少需要多少页面访问量（n）和广告点击量(m)，你才能有95%的自信说其中的一个设计比其他设计都好？



很多机器学习算法以概率论与统计学作为基础。所以对这些基础知识有清晰的概念非常重要，同时，你也要能够将这些抽象的公式与实际联系起来。



（三）数据建模和评估


▲ 奶农正试图了解影响牛奶品质的因素。他记录了每天的气温（30-40°C）、湿度（60-90%）、饲料消耗（2000-2500公斤）、牛奶产量（500-1000升）。

假设问题是要预测每天的牛奶产量，你会如何处理数据并建立模型？

这是一个什么类型的机器学习问题？



▲ 你的公司正在开发一个面部表情识别系统，这个系统接受像素为1920*1080的高清图片作为输入，接收到输入的图片后它就能告诉用户图片中的人脸处于以下哪种情绪状态：平常、高兴、悲伤、愤怒和恐惧。若图片中没有人脸时系统要能够分辨这种情况。

这属于什么类型的机器学习问题？

如果每个像素点由 3 个值来表示（RGB），那么输入数据的原始维度有多大？有办法降维吗？

你会如何对系统的输出进行编码？为什么？



▲ 在过去几个世纪里搜集到的气象数据显示温度呈循环上升和下降。对于这样的数据（年平均温度值序列），你会如何建模来预测未来 5 年的平均气温？

▲ 你的工作是收集世界各地的文章，并将来源不同的相似文章整合成一篇文章。你会如何设计这样一个系统？会用到哪些机器学习技术？



（四）应用机器学习算法与库


▲ 你在用一个给定的数据集训练一个单隐层神经网络时，发现权重在迭代训练中波动很大(变化巨大，常在正负值间摇摆)，你需要调整什么参数来解决这个问题？

▲ 支持向量机的训练在本质上是在最优化哪个值？

▲ LASSO 回归用 L1-norm 作为惩罚项，而岭回归（Ridge Regression）则使用 L2-norm 作为惩罚项。这两者哪个更有可能得到一个稀疏（某些项的系数为 0）的模型？
Ridge


▲ 当测试一个10层神经网络的反向传播时，你发现前三层的权值完全没有变化。接下来的几层（4-6）权值变化的非常缓慢。这是为什么？该如何解决?

▲ 你现在有一些关于欧洲小麦产出的数据，包括年降雨量（R，英寸），平均高度（A，米）和小麦产量（O，公斤/平方千米）。你经过粗略分析认为小麦产量与降雨量的平方以及平均海报的对数之间存在关系，即: O = β0+ β1 × R2 + β2 × loge(A)。你能使用线性回归模型计算出系数（β）吗？



你可以通过参加一些数据科学和机器学习的比赛来了解各种各样的问题和它们之间的细微差别。多多参加这些比赛，并尝试应用不同的机器学习模型。



（五）软件工程和系统设计


▲ 你在运行一个电子商务网站。当用户点击商品详细信息时，你要根据用户过去所购商品特征推荐5个用户感兴趣的商品，同时在页面底部显示。为完成这个功能你需要什么服务器和数据库？假设它们是可用的，写一个程序来获得这5个推荐商品。



▲ 你会从一个在线视频播放网站（如YouTube）上搜集什么数据来估测用户参与度和视频人气度？
人气度：
  参与度：评论，转发，浏览次数。
总浏览次数，平均每天浏览次数。


▲ 一个非常简单的垃圾邮件检测系统工作原理如下：它每次处理一封邮件并统计每个不同单词出现的频率（Term frequency），然后将这些频率与之前被标注为垃圾/正常邮件的那些频率进行比较。为扩大这一系统处理大量的电子邮件，你能设计一种能在计算机集群上运行的 Map-Reduce 方案吗？



▲你想实现用户实时使用可视化，就像热敏图一样。为实现这个功能，在客户端与服务器端你需要什么组件/服务器/API？



六、结语


很多正在准备机器学习面试的朋友往往都会沉浸在如何准备技术层面的问题上，却极少思考为什么这家公司会有这个职位，为什么公司想要用机器学习作为解决方案，为什么他们对你感兴趣？等等。


* Footnotes

[1] https://arxiv.org/pdf/1502.03167v3.pdf
