{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Tree construction\n",
    "To build a decision tree, you need to make a first decision on the dataset to dictate\n",
    "which feature is used to split the data. To determine this, you try every feature and measure which split will give you the best results. After that, you’ll split the dataset into subsets. The subsets will then traverse down the branches of the first decision node. If the\n",
    "data on the branches is the same class, then you’ve properly classified it and don’t need\n",
    "to continue splitting it. If the data isn’t the same, then you need to repeat the splitting\n",
    "process on this subset. The decision on how to split this subset is done the same way as\n",
    "the original dataset, and you repeat this process until you’ve classified all the data.\n",
    "*** Pseudo code\n",
    "\n",
    "```text\n",
    "Check if every item in the dataset is in the same class:\n",
    "If so return the class label\n",
    "Else\n",
    "find the best feature to split the data\n",
    "split the dataset\n",
    "create a branch node\n",
    "for each split\n",
    "call createBranch and add the result to the branch node\n",
    "return branch nod\n",
    "```\n",
    "\n",
    "*** Information gain\n",
    "measure of information of a set is known as Shannon entropy, entropy is defined as the expected value of the information.\n",
    "information:\n",
    "$$l(x_i) = log_2p(x_i)$$\n",
    "entropy, expected value of all the information of all posible values of our class.\n",
    "$$H=-\\sum_{i=1}^n p(x_i)log_2p(x_i)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "\n",
    "def create_data_set():\n",
    "    dataSet = [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return dataSet, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataSet, labels = create_data_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n"
     ]
    }
   ],
   "source": [
    "print(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key]) / numEntries\n",
    "        shannonEnt -= prob * log(prob, 2)\n",
    "    return shannonEnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcShannonEnt(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': 3, 'yes': 2}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numEntries = len(dataSet)\n",
    "labelCounts = {}\n",
    "# Create dictionary of all possible classes\n",
    "for featVec in dataSet:\n",
    "    currentLabel = featVec[-1]\n",
    "    if currentLabel not in labelCounts.keys():\n",
    "        labelCounts[currentLabel] = 0\n",
    "    labelCounts[currentLabel] += 1\n",
    "labelCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate entropy\n",
    "shannonEnt = 0.0\n",
    "for key in labelCounts:\n",
    "    prob = float(labelCounts[key]) / numEntries\n",
    "    shannonEnt -= prob * log(prob, 2)\n",
    "shannonEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet, axis, value):\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'yes'], [1, 'yes'], [0, 'no']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axis = 0\n",
    "value = 1\n",
    "retDataSet = []\n",
    "for featVec in dataSet:\n",
    "    if featVec[axis] == value:\n",
    "        reducedFeatVec = featVec[:axis]\n",
    "        reducedFeatVec.extend(featVec[axis+1:])\n",
    "        retDataSet.append(reducedFeatVec)\n",
    "retDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    bestInfoGain = 0.0; bestFeature = -1\n",
    "    for i in range(numFeatures):\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featList)\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        if (infoGain > bestInfoGain):\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = I\n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
